#ifndef RANLUXCL_CL
#define RANLUXCL_CL

//#pragma OPENCL EXTENSION cl_amd_printf : enable

/**** RANLUXCL v1.2.0 ****************************************

 ***** DESCRIPTION ******************************************************************

Implements the RANLUX generator of Matrin Luscher, based on the Fortran 77
implementation by Fred James. This OpenCL code along with the C++ function
ranluxcl_initialization in ranluxcl.h is a complete implementation which should
perfectly replicate the numbers generated by the original fortran77 implementation.

 ***** USAGE ************************************************************************

To use, call ranluxcl_initialization in host code. It returns a pointer to a
cl_float4 array, and also returns the size of said array in bytes. This
array should be transferred to an OpenCL buffer. See comments in
ranluxcl.hpp for more details about the initialization.

Simple sample kernel that writes a pseudorandom float4 to global memory:

#include "ranluxcl.cl"
__kernel void Kernel_PRN(__global float4* RANLUXCLTab, __global float4* PRNs)
{
        //Downloading RANLUXCLTab. The state of RANLUXCL is stored in ranluxclstate.
        ranluxcl_state_t ranluxclstate;
        ranluxcl_download_seed(&ranluxclstate, RANLUXCLTab);

        float4 randomnr = ranluxcl(&ranluxclstate);

        PRNs[get_global_id(0)] = randomnr;

        //Uploading RANLUXCLTab
        ranluxcl_upload_seed(&ranluxclstate, RANLUXCLTab);
}

The ranluxcl_download_seed and ranluxcl_upload_seed functions assume that the
RANLUXCLTab in global memory has enough values for all the work-items, i.e. that
the numWorkitems variable passed to ranluxcl_initialization in host code corresponds
to the number of work-items in the current NDRange. If this is not the case the
behaviour is, as they say, "undefined".

There are a total of four functions meant to be called by other OpenCL code:

ranluxcl_download_seed(ranluxcl_state_t *ranluxclstate, __global float4 *RANLUXCLTab)
Run at the beginning of a kernel to download ranluxcl state data

ranluxcl_upload_seed(ranluxcl_state_t *ranluxclstate, __global float4 *RANLUXCLTab)
Run at the end of a kernel to upload state data

ranluxcl(ranluxcl_state_t *ranluxclstate)
Run to generate a float4

ranluxcl_synchronize(ranluxcl_state_t *ranluxclstate)
Run to synchronize execution in case different work-items have made a different
number of calls to ranluxcl. On SIMD machines this could lead to inefficient execution.
ranluxcl_synchronize allows us to make sure all generators are SIMD-friendly again. Not
needed if all work-items always call ranluxcl the same number of times.

ranluxcl_warmup(ranluxcl_state_t *ranluxclstate)
Run once before any values are generated using ranluxcl(). This will ensure that
the parallel generators are not correlated. While you could just run this in any
kernel where ranluxcl is used, that would be wastefull. It is only necessary to
call ranluxcl_warmup once for each work-item to make sure there are no
correlations from the initialization procedure. For instance the following kernel
could be launched right after ranluxcl_initialization was called in host code:

#include "ranluxcl.cl"
__kernel void Kernel_RANLUXCL_Warmup(__global float4* RANLUXCLTab)
{
        //Downloading RANLUXCLTab. The state of RANLUXCL is stored in ranluxclstate.
        ranluxcl_state_t ranluxclstate;
        ranluxcl_download_seed(&ranluxclstate, RANLUXCLTab);

        ranluxcl_warmup(&ranluxclstate);

        //Uploading RANLUXCLTab
        ranluxcl_upload_seed(&ranluxclstate, RANLUXCLTab);
}

 ***** PERFORMANCE ******************************************************************

For luxury setting 3, performance on AMD cypress should be ~7*10^9 pseudorandom
values per second, when not downloading values to host memory (i.e. the values are
just generated, but not used for anything in particular).

 ***** IMPLEMENTATION DETAILS *******************************************************

There are two slightly different approaches combined in this file, namely planar
and planar shift. If RANLUXCL_NSKIP is set and is a multiple of 24 the planar scheme
is recovered through preprocessor directives (i.e. the unneeded parts of the
planar shift scheme are not included). If RANLUXCL_NSKIP is not set, or it is not a
multiple of 24 the planar shift scheme is used.

"Planar" refers to the fact that the algorithm is unrolled, i.e. all indexing
into the seeds is explicit. For this reason it becomes most convenient to always
discard some multiple of 24 values, i.e. the p-value should be some multiple of 24.
The idea for this approach comes from:

Vadim Demchik, Pseudo-random number generators for Monte Carlo simulations on
Graphics Processing Units, arXiv:1003.1898v1 [hep-lat]

In the planar shift scheme it is however possible to have p a multiple of 4 instead,
which allows us to avoid any resonances that might be present when p is a
multiple of the seeds table size. It also allows us to choose a p-value
corresponding to what Martin L�scher chose for his v3 version of RANLUX for our
luxury setting 4.

The planar shift algorithm is recommended (which is what is used by the default
luxury values 0 through 4 in ranluxcl_initialization), but there is a chance that
the simpler planar approach will be significantly faster on some architectures
since it includes fewer if tests and drops a switch. On AMD Cypress the
performance difference is about 10%. To use the planar approach RANLUXCL_NSKIP
must be defined in the kernel code to be the same as the nskip variable returned
by ranluxcl_initialization. If nskip is a multiple of 24 the planar scheme is
then recovered.

Note that the in24 variable is only used in planar shift, while stepnr takes the
place of in24 in the planar case.

 ***** CREDIT ***********************************************************************

I have been told by Fred James (the coder) that the original Fortran 77
implementation (which is the subject of the second paper below) is free to use and
share. Therefore I am using the MIT license (below). But most importantly please
always remember to give credit to the two articles by Martin Luscher and Fred James,
describing the generator and the fortran 77 implementation on which this
implementation is based, respectively:

Martin L�scher, A portable high-quality random number generator for lattice
field theory simulations, Computer Physics Communications 79 (1994) 100-110

F. James, RANLUX: A Fortran implementation of the high-quality pseudorandom
number generator of L�scher, Computer Physics Communications 79 (1994) 111-114

 ***** LICENSE **********************************************************************

Copyright (c) 2011 Ivar Ursin Nikolaisen

Permission is hereby granted, free of charge, to any person obtaining a copy of this
software and associated documentation files (the "Software"), to deal in the Software
without restriction, including without limitation the rights to use, copy, modify,
merge, publish, distribute, sublicense, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to the following
conditions:

The above copyright notice and this permission notice shall be included in all copies
or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A
PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF
CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

 ***************************************************************************************/

typedef struct {
    float4 s01to04;
    float4 s05to08;
    float4 s09to12;
    float4 s13to16;
    float4 s17to20;
    float4 s21to24;
    float4 carryin24stepnrnskip;
} ranluxcl_state_t;

#define RANLUXCL_TWOM24 0.000000059604644775f
#define RANLUXCL_TWOM12 0.000244140625f

//Check that nskip is a permissible value if it's defined
#ifdef RANLUXCL_NSKIP
#if RANLUXCL_NSKIP % 4 != 0
#error nskip must be divisible by 4!
#endif
#if RANLUXCL_NSKIP < 24 && RANLUXCL_NSKIP != 0
#error nskip must be either 0 or >= 24!
#endif
#if RANLUXCL_NSKIP < 0
#error nskip is negative!
#endif

//Check if planar scheme is recovered
#if RANLUXCL_NSKIP % 24 == 0
#define RANLUXCL_PLANAR
#endif

//Check if we will skip at all
#if RANLUXCL_NSKIP == 0
#define RANLUXCL_NOSKIP
#endif

#endif //defined RANLUXCL_NSKIP

//Single-value global size and id
#define RANLUXCL_NUMWORKITEMS (get_global_size(0) * get_global_size(1) * get_global_size(2))
#define RANLUXCL_MYID (get_global_id(0) + get_global_id(1) * get_global_size(0) + get_global_id(2) * get_global_size(0) * get_global_size(1))

void ranluxcl_download_seed(ranluxcl_state_t *ranluxclstate, __global float4 *RANLUXCLTab) {
    (*ranluxclstate).s01to04 = RANLUXCLTab[RANLUXCL_MYID + 0 * RANLUXCL_NUMWORKITEMS];
    (*ranluxclstate).s05to08 = RANLUXCLTab[RANLUXCL_MYID + 1 * RANLUXCL_NUMWORKITEMS];
    (*ranluxclstate).s09to12 = RANLUXCLTab[RANLUXCL_MYID + 2 * RANLUXCL_NUMWORKITEMS];
    (*ranluxclstate).s13to16 = RANLUXCLTab[RANLUXCL_MYID + 3 * RANLUXCL_NUMWORKITEMS];
    (*ranluxclstate).s17to20 = RANLUXCLTab[RANLUXCL_MYID + 4 * RANLUXCL_NUMWORKITEMS];
    (*ranluxclstate).s21to24 = RANLUXCLTab[RANLUXCL_MYID + 5 * RANLUXCL_NUMWORKITEMS];
    (*ranluxclstate).carryin24stepnrnskip = RANLUXCLTab[RANLUXCL_MYID + 6 * RANLUXCL_NUMWORKITEMS];
}

void ranluxcl_upload_seed(ranluxcl_state_t *ranluxclstate, __global float4 *RANLUXCLTab) {
    RANLUXCLTab[RANLUXCL_MYID + 0 * RANLUXCL_NUMWORKITEMS] = (*ranluxclstate).s01to04;
    RANLUXCLTab[RANLUXCL_MYID + 1 * RANLUXCL_NUMWORKITEMS] = (*ranluxclstate).s05to08;
    RANLUXCLTab[RANLUXCL_MYID + 2 * RANLUXCL_NUMWORKITEMS] = (*ranluxclstate).s09to12;
    RANLUXCLTab[RANLUXCL_MYID + 3 * RANLUXCL_NUMWORKITEMS] = (*ranluxclstate).s13to16;
    RANLUXCLTab[RANLUXCL_MYID + 4 * RANLUXCL_NUMWORKITEMS] = (*ranluxclstate).s17to20;
    RANLUXCLTab[RANLUXCL_MYID + 5 * RANLUXCL_NUMWORKITEMS] = (*ranluxclstate).s21to24;
    RANLUXCLTab[RANLUXCL_MYID + 6 * RANLUXCL_NUMWORKITEMS] = (*ranluxclstate).carryin24stepnrnskip;
}

#undef RANLUXCL_NUMWORKITEMS
#undef RANLUXCL_MYID

float ranluxcl_onestep_1(float4* vec1, float4* vec2, float4* carryin24stepnrnskip) {
    float uni, out;
    uni = (*vec1).y - (*vec2).w - (*carryin24stepnrnskip).x;
    if (uni < 0.0f) {
        uni += 1.0f;
        (*carryin24stepnrnskip).x = RANLUXCL_TWOM24;
    } else (*carryin24stepnrnskip).x = 0.0f;
    out = ((*vec2).w = uni);

    if (uni < RANLUXCL_TWOM12) out += RANLUXCL_TWOM24 * (*vec1).y;

    if (out == 0.0f) out = RANLUXCL_TWOM24 * RANLUXCL_TWOM24;
    return out;
}

float ranluxcl_onestep_2(float4* vec1, float4* vec2, float4* carryin24stepnrnskip) {
    float uni, out;
    uni = (*vec1).x - (*vec2).z - (*carryin24stepnrnskip).x;
    if (uni < 0.0f) {
        uni += 1.0f;
        (*carryin24stepnrnskip).x = RANLUXCL_TWOM24;
    } else (*carryin24stepnrnskip).x = 0.0f;
    out = ((*vec2).z = uni);

    if (uni < RANLUXCL_TWOM12) out += RANLUXCL_TWOM24 * (*vec1).x;

    if (out == 0.0f) out = RANLUXCL_TWOM24 * RANLUXCL_TWOM24;
    return out;
}

float ranluxcl_onestep_3(float4* vec1, float4* vec2, float4* carryin24stepnrnskip) {
    float uni, out;
    uni = (*vec1).w - (*vec2).y - (*carryin24stepnrnskip).x;
    if (uni < 0.0f) {
        uni += 1.0f;
        (*carryin24stepnrnskip).x = RANLUXCL_TWOM24;
    } else (*carryin24stepnrnskip).x = 0.0f;
    out = ((*vec2).y = uni);

    if (uni < RANLUXCL_TWOM12) out += RANLUXCL_TWOM24 * (*vec1).w;

    if (out == 0.0f) out = RANLUXCL_TWOM24 * RANLUXCL_TWOM24;
    return out;
}

float ranluxcl_onestep_4(float4* vec1, float4* vec2, float4* carryin24stepnrnskip) {
    float uni, out;
    uni = (*vec1).z - (*vec2).x - (*carryin24stepnrnskip).x;
    if (uni < 0.0f) {
        uni += 1.0f;
        (*carryin24stepnrnskip).x = RANLUXCL_TWOM24;
    } else (*carryin24stepnrnskip).x = 0.0f;
    out = ((*vec2).x = uni);

    if (uni < RANLUXCL_TWOM12) out += RANLUXCL_TWOM24 * (*vec1).z;

    if (out == 0.0f) out = RANLUXCL_TWOM24 * RANLUXCL_TWOM24;
    return out;
}

float4 ranluxcl(ranluxcl_state_t *ranluxclstate) {
    //ranluxcl returns a 4-component float vector where each component is uniformly distributed
    //between 0-1, end points not included.

    float4 out;

    if ((*ranluxclstate).carryin24stepnrnskip.z == 0.0f) {
        out.x = ranluxcl_onestep_1(&((*ranluxclstate).s09to12), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
        out.y = ranluxcl_onestep_2(&((*ranluxclstate).s09to12), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
        out.z = ranluxcl_onestep_3(&((*ranluxclstate).s05to08), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
        out.w = ranluxcl_onestep_4(&((*ranluxclstate).s05to08), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
        (*ranluxclstate).carryin24stepnrnskip.z += 4.0f;
    } else if ((*ranluxclstate).carryin24stepnrnskip.z == 4.0f) {
        out.x = ranluxcl_onestep_1(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
        out.y = ranluxcl_onestep_2(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
        out.z = ranluxcl_onestep_3(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
        out.w = ranluxcl_onestep_4(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
        (*ranluxclstate).carryin24stepnrnskip.z += 4.0f;
    } else if ((*ranluxclstate).carryin24stepnrnskip.z == 8.0f) {
        out.x = ranluxcl_onestep_1(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
        out.y = ranluxcl_onestep_2(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
        out.z = ranluxcl_onestep_3(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
        out.w = ranluxcl_onestep_4(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
        (*ranluxclstate).carryin24stepnrnskip.z += 4.0f;
    } else if ((*ranluxclstate).carryin24stepnrnskip.z == 12.0f) {
        out.x = ranluxcl_onestep_1(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
        out.y = ranluxcl_onestep_2(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
        out.z = ranluxcl_onestep_3(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
        out.w = ranluxcl_onestep_4(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
        (*ranluxclstate).carryin24stepnrnskip.z += 4.0f;
    } else if ((*ranluxclstate).carryin24stepnrnskip.z == 16.0f) {
        out.x = ranluxcl_onestep_1(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
        out.y = ranluxcl_onestep_2(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
        out.z = ranluxcl_onestep_3(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
        out.w = ranluxcl_onestep_4(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
        (*ranluxclstate).carryin24stepnrnskip.z += 4.0f;
    } else if ((*ranluxclstate).carryin24stepnrnskip.z == 20.0f) {
        out.x = ranluxcl_onestep_1(&((*ranluxclstate).s13to16), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        out.y = ranluxcl_onestep_2(&((*ranluxclstate).s13to16), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        out.z = ranluxcl_onestep_3(&((*ranluxclstate).s09to12), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        out.w = ranluxcl_onestep_4(&((*ranluxclstate).s09to12), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        (*ranluxclstate).carryin24stepnrnskip.z = 0.0f;

        //The below preprocessor directives are here to recover the simpler planar scheme when nskip is a multiple of 24.
        //For the most general planar shift approach, just ignore all #if's below.
#ifndef RANLUXCL_PLANAR
    }

    (*&((*ranluxclstate).carryin24stepnrnskip)).y += 4.0f;
    if ((*&((*ranluxclstate).carryin24stepnrnskip)).y == 24.0f) {
        (*&((*ranluxclstate).carryin24stepnrnskip)).y = 0.0f;
#endif //RANLUXCL_PLANAR

        int initialskips = (int) ((*ranluxclstate).carryin24stepnrnskip.z) ? (24 - (int) ((*ranluxclstate).carryin24stepnrnskip.z)) : 0;
        int bulkskips = (((int) ((*&((*ranluxclstate).carryin24stepnrnskip)).w) - initialskips) / 24) * 24;
        int remainingskips = (int) ((*&((*ranluxclstate).carryin24stepnrnskip)).w) - initialskips - bulkskips;

        //We know there won't be any initial skips in the planar scheme
#ifndef RANLUXCL_PLANAR
        //Do initial skips (lack of breaks in switch is intentional).
        switch (initialskips) {
            case(20):
                ranluxcl_onestep_1(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
            case(16):
                ranluxcl_onestep_1(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
            case(12):
                ranluxcl_onestep_1(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
            case(8):
                ranluxcl_onestep_1(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
            case(4):
                ranluxcl_onestep_1(&((*ranluxclstate).s13to16), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s13to16), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s09to12), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s09to12), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        }
#endif //RANLUXCL_PLANAR

        //Also check if we will ever need to skip at all
#ifndef RANLUXCL_NOSKIP
        for (int i = 0; i < bulkskips / 24; i++) {
            ranluxcl_onestep_1(&((*ranluxclstate).s09to12), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_2(&((*ranluxclstate).s09to12), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_3(&((*ranluxclstate).s05to08), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_4(&((*ranluxclstate).s05to08), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_1(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_2(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_3(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_4(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_1(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_2(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_3(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_4(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_1(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_2(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_3(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_4(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_1(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_2(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_3(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_4(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_1(&((*ranluxclstate).s13to16), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_2(&((*ranluxclstate).s13to16), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_3(&((*ranluxclstate).s09to12), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_4(&((*ranluxclstate).s09to12), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        }
#endif //RANLUXCL_NOSKIP

        //There also won't be any remaining skips in the planar scheme
#ifndef RANLUXCL_PLANAR
        //Do remaining skips
        if (remainingskips) {
            ranluxcl_onestep_1(&((*ranluxclstate).s09to12), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_2(&((*ranluxclstate).s09to12), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_3(&((*ranluxclstate).s05to08), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
            ranluxcl_onestep_4(&((*ranluxclstate).s05to08), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));

            if (remainingskips > 4) {
                ranluxcl_onestep_1(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
            }

            if (remainingskips > 8) {
                ranluxcl_onestep_1(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
            }

            if (remainingskips > 12) {
                ranluxcl_onestep_1(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
            }

            if (remainingskips > 16) {
                ranluxcl_onestep_1(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_2(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_3(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
                ranluxcl_onestep_4(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
            }
        }
#endif //RANLUXCL_PLANAR

        //Initial skips brought stepnr down to 0. The bulk skips did only full cycles.
        //Therefore stepnr is now equal to remainingskips.
        (*ranluxclstate).carryin24stepnrnskip.z = (float) remainingskips;
    }

    return out;
}

void ranluxcl_synchronize(ranluxcl_state_t *ranluxclstate) {
    //This function generates numbers so that the generator is at the beginning,
    //i.e. ready to generate 24 numbers before the next skipping sequence. This is
    //useful if different work-items have called ranluxcl a different number of times.
    //Since that would lead to out of sync execution it could be rather inefficient on
    //SIMD architectures like GPUs. This function thus allows us to resynchronize
    //execution across all work-items.

    //Do necessary number of calls to ranluxcl so that stepnr == 0 at the end.
    if ((*ranluxclstate).carryin24stepnrnskip.z == 4.0f)
        ranluxcl(ranluxclstate);
    if ((*ranluxclstate).carryin24stepnrnskip.z == 8.0f)
        ranluxcl(ranluxclstate);
    if ((*ranluxclstate).carryin24stepnrnskip.z == 12.0f)
        ranluxcl(ranluxclstate);
    if ((*ranluxclstate).carryin24stepnrnskip.z == 16.0f)
        ranluxcl(ranluxclstate);
    if ((*ranluxclstate).carryin24stepnrnskip.z == 20.0f)
        ranluxcl(ranluxclstate);
}

void ranluxcl_warmup(ranluxcl_state_t *ranluxclstate) {
    //This function "warms up" the generator, meaning it simply generates enough
    //values to ensure that the starting values are completely decorrelated.
    //It should be called once after ranluxcl_initialization in host code, after
    //the first call the sequences will stay uncorrelated.

    //16 is a "magic number". It is the number of times we must generate
    //a batch of 24 numbers to ensure complete decorrelation.
    for (int i = 0; i < 16; i++) {
        ranluxcl_onestep_1(&((*ranluxclstate).s09to12), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_2(&((*ranluxclstate).s09to12), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_3(&((*ranluxclstate).s05to08), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_4(&((*ranluxclstate).s05to08), &((*ranluxclstate).s21to24), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_1(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_2(&((*ranluxclstate).s05to08), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_3(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_4(&((*ranluxclstate).s01to04), &((*ranluxclstate).s17to20), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_1(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_2(&((*ranluxclstate).s01to04), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_3(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_4(&((*ranluxclstate).s21to24), &((*ranluxclstate).s13to16), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_1(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_2(&((*ranluxclstate).s21to24), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_3(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_4(&((*ranluxclstate).s17to20), &((*ranluxclstate).s09to12), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_1(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_2(&((*ranluxclstate).s17to20), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_3(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_4(&((*ranluxclstate).s13to16), &((*ranluxclstate).s05to08), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_1(&((*ranluxclstate).s13to16), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_2(&((*ranluxclstate).s13to16), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_3(&((*ranluxclstate).s09to12), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
        ranluxcl_onestep_4(&((*ranluxclstate).s09to12), &((*ranluxclstate).s01to04), &((*ranluxclstate).carryin24stepnrnskip));
    }

}

#undef RANLUXCL_TWOM24
#undef RANLUXCL_TWOM12
#endif //RANLUXCL_CL

struct sysdata {
    int NP;
    int NPc;
    int NPstep;
    int nx;
    int lbc_flag;
    int steps;
    float lx;
    float dx;
    float n0;
    float sig_t;
    float sig_s;
    float prob_s;
    float Jp_l;
    float eps;
    float q0_lo;
    float D;
    unsigned long NP_tot;
#ifndef NVIDIA
}  __attribute__((aligned(8))) ;
#else
};
#endif

inline float absdistcalc(int j, int st, int fn, float x0, float xf, float cellsize) {
    float rightface = (j + 1) * cellsize;
    float leftface = j*cellsize;
    float val;
    if (st == fn) {
        val = xf - x0;
    } else if (j == st) {
        val = rightface - x0;
    } else if (j == fn) {
        val = xf - leftface;
    } else {
        val = cellsize;
    }
    return val;
}

inline float2 f2_quick_two_sum(float a, float b) {
    float s;
    s = a + b;

    return (float2) {
        s, b - (s - a)
    };
}

/* Computes fl(a+b) and err(a+b).  */
inline float2 f2_two_sum(float a, float b) {
    float2 retval;
    float bb;

    retval.x = a + b;
    bb = retval.x - a;
    retval.y = (a - (retval.x - bb)) + (b - bb);

    return retval;
}

#ifdef DOUBLE

inline double f2_f2_add_f2(const double a, const double b) {
    return a + b;
}
#else

/* ss(C) = ss(a) + ss(b) */
inline float2 f2_f2_add_f2(const float2 a, const float2 b) {
    /* containers and temporary variables */
    float2 temp, retval;

    /* perform ss arithmetic */
    retval = f2_two_sum(a.x, b.x);
    temp = f2_two_sum(a.y, b.y);
    retval.y += temp.x;
    retval = f2_quick_two_sum(retval.x, retval.y);
    retval.y += temp.y;
    retval = f2_quick_two_sum(retval.x, retval.y);

    return retval;
}
#endif

/*
 Exceedingly simple thread-per-address float2 zero-initializer
 */
#ifdef DOUBLE

__kernel void resetSaveHist(__global double * saveHist) {
    saveHist[get_global_id(0)] = 0.0;
}
#else

__kernel void resetSaveHist(__global float2 * saveHist) {

    saveHist[get_global_id(0)] = (float2){0.0f, 0.0f};
}
#endif

/*
 Call once to ensure decorrelation of the random number generator
 */
__kernel void Kernel_RANLUXCL_Warmup(__global float4* RANLUXCLTab) {
    //Downloading RANLUXCLTab. The state of RANLUXCL is stored in ranluxclstate.
    ranluxcl_state_t ranluxclstate;
    ranluxcl_download_seed(&ranluxclstate, RANLUXCLTab);

    ranluxcl_warmup(&ranluxclstate);

    //Uploading RANLUXCLTab
    ranluxcl_upload_seed(&ranluxclstate, RANLUXCLTab);
}

/*
 Monte Carlo particle generation
 Each thread produces 32 values (for now, we may make this more adjustable)
 */
__kernel void xmcKern(__constant struct sysdata * data, __global float * mu0, __global float * x0, __global float * xf, __global int * cell0, __global int * cellf, __global float * wx, __constant float * Qbar, __global float4* RANLUXCLTab) {

    //initialize simulation parameters
    int i, mycell0, mycellf;
    float tempPos;
    float myx0, myxf;
    float mymu0;
    float ransave[3]; //so we don't have to "waste" the 4th random number
    float4 randoms;

    //get our random generator state
    ranluxcl_state_t ranluxclstate;
    ranluxcl_download_seed(&ranluxclstate, RANLUXCLTab);

    for (i = 0; i < 64; i++) {

        //our random number generator returns blocks of 4 random floats
        //but we only need 3 per iteration, so we pack the "spare" into an extra
        //array, which we use as the random value every 4th iteration
        //We use bit masking to avoid expensive modulo operations
        if ((i + 1) & 3) {
            randoms = ranluxcl(&ranluxclstate);
            ransave[i & 3] = randoms.w;
        } else {
            randoms = (float4){ransave[0], ransave[1], ransave[2], 0.0f};
        }

        //initial particle position and direction
        myx0 = ((get_global_id(0) + i * get_global_size(0)) / (data->NPc>>1) + randoms.x) * data->dx;
        mymu0 =  randoms.y;
        mymu0 = (mymu0 >= data->eps) ? mymu0 : data->eps * 0.5f;
        mymu0 = (i < 32) ? -mymu0 : mymu0; //exactly half go left, and half go right
        myx0 -= (i < 32) ? 0 : data->lx; //initial position is calculated as if the rightbound half are in a "second system", directly after the leftbound half, so we need to scale
        //determine which cell the particles initially resided in
        mycell0 = ((int) ceil(myx0 / data->dx)) - 1;
        //any particles below the lower bound are protected from segfaults
        //realistically, we can have at worst 0.0f here, causing -1
        //but this ternary handles it, no need to bound top, it's built into the
        //above calculation
        mycell0 = (mycell0 >= 0) ? mycell0 : 0;

        //particle velocity and destination calculation
        //tempPos is first the velocity, then the position, to save registers
        tempPos = (-log(randoms.z) / data->sig_t);
        tempPos = myx0 + mymu0 * tempPos;

        //if we leave the system, set us on the system boundary
        myxf = (tempPos >= data->lx) ? data->lx : ((tempPos <= 0.0f) ? 0.0f : tempPos);

        //determine which cell particles landed in after the flight
        mycellf = ((int) ceil(myxf / data->dx)) - 1;
        mycellf = (mycellf >= 0) ? mycellf : 0;

        //implicitly coalesced global writes
        mu0[get_global_id(0) + i * get_global_size(0)] = mymu0;
        wx[(get_global_id(0) + i * get_global_size(0))] = fabs(Qbar[mycell0] * data->lx);
        //regardless of where a particle starts and ends,
        // make sure x0 and cell0 are the leftmost position
        // and xf and cellf are the rightmost
        if (i < 32) {
        x0[get_global_id(0) + i * get_global_size(0)] =  myxf;
        xf[get_global_id(0) + i * get_global_size(0)] =  myx0;
        cell0[get_global_id(0) + i * get_global_size(0)] = mycellf;
        cellf[get_global_id(0) + i * get_global_size(0)] = mycell0;
        } else {
        x0[get_global_id(0) + i * get_global_size(0)] = myx0;
        xf[get_global_id(0) + i * get_global_size(0)] = myxf;
        cell0[get_global_id(0) + i * get_global_size(0)] = mycell0;
        cellf[get_global_id(0) + i * get_global_size(0)] = mycellf;

        }
    }

    //update our random number generator state
    ranluxcl_upload_seed(&ranluxclstate, RANLUXCLTab);
}

/*
 * Uses 1024 threads to reduce 1024 3-member float2 values stored in shared memory.
 * Assumes member 0 occupies shared memory regions 0-1023
 * Assumes member 1 occupies shared memory regions 1024-2047
 * Assumes member 2 occupies shared memory regions 2048-3071
 * After complete reduction, threads 0-2 write the values contiguously to
 * the memory pointed to by storagecell
 *
 * The "first tier" reduce starts on members 0 and 1 to fill the workgroup,
 * then the "second tier" of reduce starts work on member 2 once threads are
 * available. All other tiers have "dead threads" with no work to do.
 */
#ifdef DOUBLE

void triple1024sharedreducewrite(__local double * sharedbuff, __global double * storagecell, int shareID) {
#else

void triple1024sharedreducewrite(__local float2 * sharedbuff, __global float2 * storagecell, int shareID) {
#endif
    //wait for all workgroup threads to finish initializing shared memory.
    barrier(CLK_LOCAL_MEM_FENCE);

    //threads 0-511 do the first tier of member 0 threads 512-1023 do member 1
    if (shareID < 512) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 512]);
    } else {
        sharedbuff[shareID + 512] = f2_f2_add_f2(sharedbuff[shareID + 512], sharedbuff[shareID + 1024]);
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    //members 0 and 1 are done on threads 0-255 and 256-511 respectively
    //start member 2 on threads 512-1023
    if (shareID < 256) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 256]);
    } else if (shareID < 512) {
        sharedbuff[shareID + 768] = f2_f2_add_f2(sharedbuff[shareID + 768], sharedbuff[shareID + 1024]);
    } else {
        sharedbuff[shareID + 1536] = f2_f2_add_f2(sharedbuff[shareID + 1536], sharedbuff[shareID + 2048]);
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    if (shareID < 128) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 128]);
    } else if (shareID < 256) {
        sharedbuff[shareID + 896] = f2_f2_add_f2(sharedbuff[shareID + 896], sharedbuff[shareID + 1024]);
    } else if (shareID < 512) {
        sharedbuff[shareID + 1792] = f2_f2_add_f2(sharedbuff[shareID + 1792], sharedbuff[shareID + 2048]);
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    if (shareID < 64) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 64]);
    } else if (shareID < 128) {
        sharedbuff[shareID + 960] = f2_f2_add_f2(sharedbuff[shareID + 960], sharedbuff[shareID + 1024]);
    } else if (shareID < 256) {
        sharedbuff[shareID + 1920] = f2_f2_add_f2(sharedbuff[shareID + 1920], sharedbuff[shareID + 2048]);
    }
    barrier(CLK_LOCAL_MEM_FENCE);
    if (shareID < 32) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 32]);
    } else if (shareID < 64) {
        sharedbuff[shareID + 992] = f2_f2_add_f2(sharedbuff[shareID + 992], sharedbuff[shareID + 1024]);
    } else if (shareID < 128) {
        sharedbuff[shareID + 1984] = f2_f2_add_f2(sharedbuff[shareID + 1984], sharedbuff[shareID + 2048]);
    }
    barrier(CLK_LOCAL_MEM_FENCE);

    //this round forces each of the three reductions into separate warps
    //to avoid paying both the divergence and synchronization cost
    //since sync is required anyway
    if (shareID < 16) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 16]);
    } else if (shareID < 48 && shareID >= 32) {
        sharedbuff[shareID + 992] = f2_f2_add_f2(sharedbuff[shareID + 992], sharedbuff[shareID + 1008]);
    } else if (shareID < 96 && shareID >= 64) {
        sharedbuff[shareID + 1984] = f2_f2_add_f2(sharedbuff[shareID + 1984], sharedbuff[shareID + 2016]);
    }
    barrier(CLK_LOCAL_MEM_FENCE);


    //no more barriers are needed, take advantage of warp-level synchronization
    //if you have any intentions of running this code on CPU, you must insert
    //barriers between tiers
    //We'll tolerate the slight divergence to save having to sync
    if (shareID < 8) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 8]);
    } else if (shareID < 16) {
        sharedbuff[shareID + 1016] = f2_f2_add_f2(sharedbuff[shareID + 1016], sharedbuff[shareID + 1024]);
    } else if (shareID < 32) {
        sharedbuff[shareID + 2032] = f2_f2_add_f2(sharedbuff[shareID + 2032], sharedbuff[shareID + 2048]);
    }
    if (shareID < 4) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 4]);
    } else if (shareID < 8) {
        sharedbuff[shareID + 1020] = f2_f2_add_f2(sharedbuff[shareID + 1020], sharedbuff[shareID + 1024]);
    } else if (shareID < 16) {
        sharedbuff[shareID + 2040] = f2_f2_add_f2(sharedbuff[shareID + 2040], sharedbuff[shareID + 2048]);
    }
    if (shareID < 2) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 2]);
    } else if (shareID < 4) {
        sharedbuff[shareID + 1022] = f2_f2_add_f2(sharedbuff[shareID + 1022], sharedbuff[shareID + 1024]);
    } else if (shareID < 8) {
        sharedbuff[shareID + 2044] = f2_f2_add_f2(sharedbuff[shareID + 2044], sharedbuff[shareID + 2048]);
    }
    if (shareID == 0) {
        sharedbuff[shareID] = f2_f2_add_f2(sharedbuff[shareID], sharedbuff[shareID + 1]);
    } else if (shareID == 1) {
        sharedbuff[shareID + 1023] = f2_f2_add_f2(sharedbuff[shareID + 1023], sharedbuff[shareID + 1024]);
    } else if (shareID < 4) {
        sharedbuff[shareID + 2046] = f2_f2_add_f2(sharedbuff[shareID + 2046], sharedbuff[shareID + 2048]);
    }

    //member 2 is "one-tier" behind members 0 and 1..
    if (shareID == 2) {
        sharedbuff[shareID + 2046] = f2_f2_add_f2(sharedbuff[shareID + 2046], sharedbuff[shareID + 2047]);
    }

    //global write ("mostly" coalesced);
    if (shareID < 3) {

        storagecell[shareID] = sharedbuff[shareID << 10];
    }
}

__kernel void cell1024Kern(__constant struct sysdata * data, __global float * mu0, __global float * x0, __global float * xf, __global int * cell0, __global int * cellf, __global float * wx,
#ifdef DOUBLE
        __global double * subtallies
#else
        __global float2 * subtallies) {
#endif

    //write is a write-mask to determine if the given particle actually interacts
    //with this cell/boundary, the work is still done if they don't, but we
    //just add a zero value instead.
    int i, write;
    int mycell0, mycellf;
    float abseps;
    float weight;
    float myx0, myxf;
    float sign;
    float absdist;
    float absepsinv;
    unsigned long memoffset = get_local_id(0);

#ifdef DOUBLE
    __local double ourtallies[3072];

    //initialize the local memory this thread will be using
    ourtallies[get_local_id(0)] = 0.0;
    ourtallies[get_local_id(0) + 1024] = 0.0;
    ourtallies[get_local_id(0) + 2048] = 0.0;
#else
    __local float2 ourtallies[3072];

    //initialize the local memory this thread will be using
    ourtallies[get_local_id(0)] = (float2){0.0f, 0.0f};
    ourtallies[get_local_id(0) + 1024] = (float2){0.0f, 0.0f};
    ourtallies[get_local_id(0) + 2048] = (float2){0.0f, 0.0f};
#endif



    if (get_group_id(0) == 0) {
        //left edge
        //each of the 1024 threads has to loop over a subset of the data
        while (memoffset < (data->NP >> 1)) {

            //all these reads should be implicitly coalesced
            weight = wx[memoffset];
            abseps = mu0[memoffset];
            myx0 = x0[memoffset];

            sign = copysign(1.0f, abseps);
            abseps = fabs(abseps);
            absepsinv = 1.0f / abseps;

            write = (myx0 <= 0.0f);
#ifdef DOUBLE
            ourtallies[get_local_id(0)] = f2_f2_add_f2(write ? weight * absepsinv : 0.0f, ourtallies[get_local_id(0)]);

            ourtallies[get_local_id(0) + 1024] = f2_f2_add_f2(write ? weight * abseps : 0.0f, ourtallies[get_local_id(0) + 1024]);

            ourtallies[get_local_id(0) + 2048] = f2_f2_add_f2(write ? sign * weight : 0.0f, ourtallies[get_local_id(0) + 2048]);
#else

            ourtallies[get_local_id(0)] = f2_f2_add_f2((float2) {
                write ? weight * absepsinv : 0.0f, 0.0f
            }, ourtallies[get_local_id(0)]);

            ourtallies[get_local_id(0) + 1024] = f2_f2_add_f2((float2) {
                write ? weight * abseps : 0.0f, 0.0f
            }, ourtallies[get_local_id(0) + 1024]);

            ourtallies[get_local_id(0) + 2048] = f2_f2_add_f2((float2) {
                write ? sign * weight : 0.0f, 0.0f
            }, ourtallies[get_local_id(0) + 2048]);
#endif
            memoffset += 1024;
        }
    } else if (get_group_id(0) == 1) {
        //right edge
        memoffset += (data->NPc >> 1)*(data->nx);

        //each of the 1024 threads has to loop over a subset of the data

        while (memoffset < (data->NP )) { // >> 1)) {

            //all these reads should be implicitly coalesced
            weight = wx[memoffset];
            abseps = mu0[memoffset];
            myxf = xf[memoffset];

            sign = copysign(1.0f, abseps);
            abseps = fabs(abseps);
            absepsinv = 1.0f / abseps;
            write = (myxf >= data->lx);

#ifdef DOUBLE
            ourtallies[get_local_id(0)] = f2_f2_add_f2(write ? weight * absepsinv : 0.0f, ourtallies[get_local_id(0)]);

            ourtallies[get_local_id(0) + 1024] = f2_f2_add_f2(write ? weight * abseps : 0.0f, ourtallies[get_local_id(0) + 1024]);

            ourtallies[get_local_id(0) + 2048] = f2_f2_add_f2(write ? wign * weight : 0.0f, ourtallies[get_local_id(0) + 2048]);
#else

            ourtallies[get_local_id(0)] = f2_f2_add_f2((float2) {
                write ? weight * absepsinv : 0.0f, 0.0f
            }, ourtallies[get_local_id(0)]);

            ourtallies[get_local_id(0) + 1024] = f2_f2_add_f2((float2) {
                write ? weight * abseps : 0.0f, 0.0f
            }, ourtallies[get_local_id(0) + 1024]);

            ourtallies[get_local_id(0) + 2048] = f2_f2_add_f2((float2) {
                write ? sign * weight : 0.0f, 0.0f
            }, ourtallies[get_local_id(0) + 2048]);
#endif
            memoffset += 1024;
        }
    } else {
        //interior cell
        //each of the 1024 threads has to loop over a subset of the data
        memoffset += (((get_group_id(0)-2)*(data->NPc>>1)) & (~1023)) ;
  //      long jumpoffset = memoffset + (((data->NPc>>1)*(get_group_id(0)-1) +1023) & (~1023)); //precompute the memoffset when we need to jump from rightbound to leftbound particles
  //      jumpoffset -= (jumpoffset -1024 > (data->NPc>>1)*(get_group_id(0)-1)) ? 1024 : 0; //account for rounding up in the previous calculation, or there can be a slight miscalculation where some leftbound particles aren't counted
  //      jumpoffset = -1;
        for (i = (((data->NPc>>1)*(data->nx +1) + 1023) >> 10); i >0; i--) {

          //  if (memoffset > ((data->NPc >> 1)*(get_group_id(0) - 1)) && memoffset < ((data->NPc >> 1)*((get_group_id(0)+get_num_groups(0)) - 4))) {
       //     if (memoffset == jumpoffset) {
        //        memoffset += ((data->NPc >> 1)*(data->nx - 1));
       //     }
            //all these reads should be implicitly coalesced
            weight = wx[memoffset];
            abseps = mu0[memoffset];
            myx0 = x0[memoffset];
            myxf = xf[memoffset];
            mycell0 = cell0[memoffset];
            mycellf = cellf[memoffset];

            sign = copysign(1.0f, abseps);
            abseps = fabs(abseps);
            absepsinv = 1.0f / abseps;

            write = ((get_group_id(0) - 2) >= mycell0 && (get_group_id(0) - 2) <= mycellf);

            absdist = absdistcalc((get_group_id(0) - 2), mycell0, mycellf, myx0, myxf, data->dx);
#ifdef DOUBLE
            ourtallies[get_local_id(0)] = f2_f2_add_f2(write ? weight * absdist * absepsinv : 0.0f, ourtallies[get_local_id(0)]);

            ourtallies[get_local_id(0) + 1024] = f2_f2_add_f2(write ? weight * weight * absdist * absdist * absepsinv * absepsinv : 0.0f, ourtallies[get_local_id(0) + 1024]);

            ourtallies[get_local_id(0) + 2048] = f2_f2_add_f2((float2) {
                write ? weight * absdist * abseps : 0.0f, 0.0f
            }, ourtallies[get_local_id(0) + 2048]);
#else
//
            ourtallies[get_local_id(0)] = f2_f2_add_f2((float2) {
//                write ? 1.0f : 0.0f, 0.0f
                write ? weight * absdist * absepsinv : 0.0f, 0.0f
            }, ourtallies[get_local_id(0)]);

            ourtallies[get_local_id(0) + 1024] = f2_f2_add_f2((float2) {
                write ? weight * weight * absdist * absdist * absepsinv * absepsinv : 0.0f, 0.0f
//                write ? 2.0f : 0.0f, 0.0f
            }, ourtallies[get_local_id(0) + 1024]);

            //
            ourtallies[get_local_id(0) + 2048] = f2_f2_add_f2((float2) {
                write ? weight * absdist * abseps : 0.0f, 0.0f
//                write ? 3.0f : 0.0f, 0.0f
            }, ourtallies[get_local_id(0) + 2048]);
#endif
            memoffset += 1024;
        }
    }



    //local memory reduce of all three data members across the entire workgroup
    triple1024sharedreducewrite(&ourtallies[0], &subtallies[get_group_id(0)*3], get_local_id(0));

}